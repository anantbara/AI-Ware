---
layout: default
title: ChatBot v.1.0
---

# Build your ChatBot (Part-2)
Our life is not what it once was. Today we are completely surrounded with technologies which makes our life simpler and easier. That’s why it’s normal for us to interact with technologies via. Touch, Gesture or Voice communication. ChatBot which provides a way to interact with technologies or customers naturally is quite popular. To know more about ChatBot, please go through this [link](https://anantbara.github.io/ProjectPages/project-1_t1.html) where I have given the detailed introduction about ChatBot. In last session, I promised you to answer the very common question i.e. “How and where to start”. In this article which is the last part of the “Build your ChatBot” series, we are going to see the practical side of ChatBot development where we will collect and preprocess the data and build the model. The very first thing you need for this solution is Data. That’s why I would like to talk about Data Gathering first.

**For the project code, you can _[click here](https://github.com/anantbara/ChatBot-v.1.0)_**

### _Data Gathering:_
Data gathering is no rocket science. It totally depends on developer’s requirement. There are 3 ways to gather the data:
1. Manually prepare the sample dataset which includes all variations. 
2. Many organizations/companies like Kaggle, UCI, etc. which prepare the cleaned dataset and share on internet for free. 
3. If you are good in script writing in any language, then you can create your own crawler to extract unstructured information from any webpage. 
Also there are many companies which prepare and sell the dataset. If your ChatBot project really needs large dataset then you can go for this option too, since it requires less time for preprocessing step and provides maximum accuracy.


### _Data Preprocessing:_
Actually for a programmer, this is the starting point of the ChatBot development. This is stage where a developer needs the utmost attention because data is very sensitive to accuracy and handling them is quite complex. For Data preprocessing, we need a person with good understanding of data and its significance. Always remember that we need to understand the need for data which can help us to improve the training of our ChatBot as well as increase the overall accuracy. For demo purpose, we are going to create a ChatBot which greets the customer. As Chatbot is all about **Statement** and its **Responses**, so we have to arrange the data and prepare 2 columns (one for Statement and other for responses). We can also prepare this in JSON format where key and value will be Statement and Response respectively. You have full freedom to choose either of them. 

Now many of you may think that ‘what is complex in this stage, anyone can do this in no time’. But my friend, the preprocessing step is still not over. From here, the actual preprocessing is going to start. It is very difficult to cover all the preprocessing steps here because what preprocessing steps are required depends on data format. The data can be of any type that will be arranged in many ways like tables, where you have some columns and its values can be numbers/words. Below are the screenshot of Titanic dataset which is in table format.

![alt text](/images/titanic_dataset.png "Titanic Dataset Screenshot")

Now it’s a good time to go deep into preprocessing concept. Preprocessing consists of various small tasks which need not be performed, all of them always. The most common preprocessing steps are as follows:
1. Data cleaning
2. Data integration
3. Data transformation

Let’s go through all these steps in detail with example code. For this you need to install Python and few packages like NLTK and Scikit-Learn. Assuming that you have some knowledge of python and you can do this installation step by step on your own. For those who don’t have python knowledge, can find an alternative code/approach in their respective languages. Below figure shows the screenshot of our dataset on which we will be doing all preprocessing steps.

![alt text](/images/dataset.png "Chatbot Dataset Screenshot")

### _Data cleaning:_
In this step, we will fill in missing values, smooth noisy data, identify or remove outliers, and resolve inconsistencies if any. In our case we may have special characters which are useless and that’s why we have to remove them.

![alt text](/images/clean_data.png "Clean dataset function")

### _Data Integration:_
If you have heard about this term “Big Data” then you might have an idea about how the data are stored in cloud/cluster. Here for the demo, I am going to extract data from 2 different files and integrate into one file. If you have chat dataset in multiple files then you can use below code to integrate into one dataset.

![alt text](/images/data_integration.png "Data integration function")

### _Data Transformation:_
Right now you have done the cleaning and integration of data. We have to extract features from each text sentences because not all words are important. And also we have to represent these features into numeric data i.e. also known as vectoring data. There are several ways to do this like 1-hot encoding, Word Embedding (Word vectors), TFIDF etc. But we are going to use TFIDF because you can easily get a package to calculate TFIDF in any programming language.

![alt text](/images/data_transformation.png "Data transformation function")

If you have noticed in the above code, I have created a whitelist of words that is used to ask questions. Because TfidfVectorizer function removes all stop words, we need to add this whitelisted words to our feature list.

That’s all. We have completed all the necessary steps that is required for our ChatBot. But always remember one thing that there are some other preprocessing steps which I have not covered in this article because that is not applicable for our ChatBot. I have just given an idea on how to approach for a ChatBot solution. Now the model is ready and you can also save this model in your local disk, if you want. 

![alt text](/images/pickle.png "Save state function")

Now you might be thinking, ‘how this model will help us in our ChatBot project and how to use them’. So the answer is __“Cosine similarity”__. You don’t have to write any Cosine Similarity function because it’s already available in scikit-learn package. You just have to transform your test query and pass this to Cosine Similarity function along with our model object. It will return the similarity score but we are only interested in entry having the highest score. To get the better result you can tweak the threshold value.

![alt text](/images/test.png "Testing chatbot function")

There are numerous problems with this approach and I know you might not be getting correct output always. This is because it is one of the very basic way to build any ChatBot. There are other methods too which are way more efficient and accurate than this. In the coming weeks, you will get the updated version of ChatBot development using some 3rd party packages or Deep learning.
